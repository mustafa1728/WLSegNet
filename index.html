<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head>
  <title>A Language-Guided Benchmark for Weakly Supervised Open Vocabulary Semantic Segmentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<meta property="og:title" content="A Language-Guided Benchmark for Weakly Supervised Open Vocabulary Semantic Segmentation" />

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-167124286-2', 'auto');
ga('send', 'pageview');
</script>
<!-- <script src="lib.js" type="text/javascript"></script>
<script src="popup.js" type="text/javascript"></script> -->

<script type="text/javascript">
// redefining default features
var _POPUP_FEATURES = 'width=500,height=300,resizable=1,scrollbars=1,titlebar=1,status=1';
</script>
<!-- <link media="all" href="glab.css" type="text/css" rel="StyleSheet"> -->
<style type="text/css" media="all">
IMG {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 0px;
	FLOAT: right;
	PADDING-BOTTOM: 0px;
	PADDING-TOP: 0px
}
#primarycontent {
	MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
1000? "1000px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
1000px }
BODY {
	TEXT-ALIGN: center
}
</style>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 0px;
    width: 100%;
  }

  h1 {
    font-weight:300;
  }

  div {
    max-width: 95%;
    margin:auto;
    padding: 10px;
  }

  .table-like {
    display: flex;
    flex-wrap: wrap;
    flex-flow: row wrap;
    justify-content: center;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img {
    padding: 0;
    display: block;
    margin: 0 auto;
    max-height: 100%;
    max-width: 100%;
  }

  iframe {
    max-width: 100%;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    max-width: 1100px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>

<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';
  }
</script>

<body>

<div id="primarycontent">
<center><h1 style="font-size: 225%">A Language-Guided Benchmark for Weakly Supervised Open Vocabulary Semantic Segmentation</h1></center>
<center>
  <!-- First row --->
  <div class="table-like" style="max-width:880px;margin:auto;">
    
    <div>
      <center>
        <a href="https://github.com/prinshul" style="font-size: larger">Prashant Pandey</a>
      </center>
      <center>
        Indian Institute of Technology Delhi
      </center>
    </div>
    
    <div>
      <center>
        <a href="https://github.com/mustafa1728" style="font-size: larger">Mustafa Chasmai</a>
      </center>
      <center>
        Indian Institute of Technology Delhi
      </center>
    </div>
    
    <div>
      <center>
        <a href="https://github.com/Monish-Natarajan" style="font-size: larger">Monish Natarajan</a>
      </center>
      <center>
        Indian Institute of Technology Kharagpur
      </center>
    </div>
    
    <div>
      <center>
        <a href="https://scholar.google.com/citations?user=7EnEz7gaXWcC&hl=en" style="font-size: larger">Brejesh Lall</a>
      </center>
      <center>
        Indian Institute of Technology Delhi
      </center>
    </div>
    
  </div>

  <!-- Second row --->




<div class="table-like" style="justify-content:space-evenly;max-width:900px;margin:auto;">
  <center>
    <table>
      <tr>
        <!-- <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://link.springer.com/chapter/10.1007/978-3-031-16452-1_8">[Paper]</a>
        </td>-->
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://arxiv.org/abs/2302.14163">[Arxiv]</a>
        </td> 
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://github.com/mustafa1728/WLSegNet">[Code]</a>
        </td>
      </tr>
    </table>
  </center>
</div>
<center>
<br>


<center>
    <table border="0" cellspacing="0" cellpadding="0">
      <tr>
        <td align="center" valign="bottom" style="max-width:800px">
            <img class="result" src="assets/setting.png" style="width: 100%">
        </td>
      </tr>
    </table>
    </center>

    <br/>
    <br/>

<h2>Abstract</h2>
<div style="font-size:16px; text-align: justify;max-width:700px">
<p>
    Increasing attention is being diverted to data-efficient problem settings like Open Vocabulary Semantic Segmentation (OVSS) which deals with segmenting an arbitrary object that may or may not be seen during training. The closest standard problems related to OVSS are Zero-Shot and Few-Shot Segmentation (ZSS, FSS) and their Cross-dataset variants where zero to few annotations are needed to segment novel classes. The existing FSS and ZSS methods utilize fully supervised pixel-labelled seen classes to segment unseen classes. Pixel-level labels are hard to obtain, and using weak supervision in the form of inexpensive image-level labels is often more practical. To this end, we propose a novel unified weakly supervised OVSS pipeline that can perform ZSS, FSS and Cross-dataset segmentation on novel classes without using pixel-level labels for either the base (seen) or the novel (unseen) classes in an inductive setting. We propose Weakly-Supervised Language-Guided Segmentation Network (WLSegNet), a novel language-guided segmentation pipeline that i) learns generalizable context vectors with batch aggregates (mean) to map class prompts to image features using frozen CLIP (a vision-language model) and ii) decouples weak ZSS/FSS into weak semantic segmentation and Zero-Shot segmentation. The learned context vectors avoid overfitting on seen classes during training and transfer better to novel classes during testing. WLSegNet avoids fine-tuning and the use of external datasets during training. The proposed pipeline beats existing methods for weak gen- eralized Zero-Shot and weak Few-Shot semantic segmentation by 39 and 3 mIOU points respectively on PASCAL VOC and weak Few-Shot semantic segmentation by 5 mIOU points on MS COCO. On a harder setting of 2- way 1-shot weak FSS, WLSegNet beats the baselines by 13 and 22 mIOU points on PASCAL VOC and MS COCO, respectively. Without using dense pixel-level annotations, our results for MS COCO ZSS are comparable to fully supervised ZSS methods. We also benchmark weakly supervised Cross- dataset Segmentation.
</p>
</div>

<center>
    <table border="0" cellspacing="0" cellpadding="0">
      <tr>
        <td align="center" valign="bottom" style="max-width:800px">
            <img class="result" src="assets/prompt_learning.jpg" style="width: 100%">
        </td>
      </tr>
    </table>
</center>

<h2>Citation</h2>
<pre style="font-size:14px; text-align: left;max-width:700px;overflow-x: scroll;background-color:beige;border-color: rgb(192, 192, 192);border-width: 2px;border-radius: 10px;border-style:solid;">
    <code>
  @article{pandey2023language,
      title={A Language-Guided Benchmark for Weakly Supervised Open Vocabulary Semantic Segmentation},
      author={Pandey, Prashant and Chasmai, Mustafa and Natarajan, Monish and Lall, Brejesh},
      journal={arXiv preprint arXiv:2302.14163},
      year={2023}
  }
    </code>
</pre>


</body>

</html>